\documentclass{article}

\usepackage[utf8]{inputenc}%(only for the pdftex engine)
%\RequirePackage[no-math]{fontspec}[2017/03/31]%(only for the luatex or the xetex engine)
\usepackage[english,ngerman]{babel}
\usepackage[small]{dgruyter}
\usepackage{microtype}

\usepackage[%
style=authoryear,%
autolang=other,%
sorting=nty,%
sortlocale=de_DE,%
autopunct=true,%
uniquename=init,%
eprint=false,%
isbn=false,%
hyperref=false,%
backend=biber]{biblatex}
\bibliography{referatory,meine}

%  Was in bibliographischen Angaben nicht angezeigt werden soll:
\newcommand*{\CleanUpReferatory}{%
  \iffieldequalstr{eprinttype}{googlebooks}{%
    \clearfield{eprint}%
    \clearfield{eprinttype}}{}}%
\newcommand*{\CLclean}{%
  \ifkeyword{CL}{%
    \clearfield{addendum}}{}}%
\AtEveryCitekey{\CleanUpReferatory\CLclean}
\AtEveryBibitem{\CleanUpReferatory\CLclean}%

% Bibliographischer Stil:
\renewcommand*{\labelnamepunct}{\adddot\space}%
\renewbibmacro*{publisher+location+date}{%
  \printlist{publisher}%
  \setunit*{\addcomma\space}%
  \printlist{location}%
  \setunit*{\addspace}%
  \usebibmacro{date}%
  \newunit}%
\DeclareFieldFormat[article]{title}{#1}%
\DeclareFieldFormat[incollection]{title}{#1}%
\DeclareFieldFormat*{pages}{#1}%
\renewcommand*{\bibpagespunct}{\addcolon}%
\renewbibmacro{in:}{}%
\usepackage{xpatch}
\xpatchbibmacro{date+extradate}{%
  \printtext[parens]%
}{%
  \setunit*{\adddot\space}%
  \printtext%
}{}{} 

%% spezielle Macros fuer diesen Text
\newcommand*{\lit}{\textit}%
\newcommand*{\vokabular}{\texttt}%
\newcommand*{\englisch}[1]{\foreignlanguage{english}{\textit{#1}}}%
\newcommand*{\latein}{\textit}%
\newcommand*{\som}{\texttt{standoff-mode}}%
\renewcommand*{\see}{\autocap{v}gl\adddot}%

\begin{document}

  \articletype{...}% FIXME

  \author*[1]{Christian Lück}%
  \runningauthor{Christian Lück}%
  \affil[1]{FernUniversität in Hagen}%
  \title{Beispiele Annotieren}%
  \runningtitle{Beispiele Annotieren}%
  \subtitle{...}%
  \abstract{...}%
  \keywords{Annotationen, Literaturwissenschaft, Philosophie}%
  \classification[PACS]{...}
  \communicated{...}
  \dedication{...}
  \received{...}
  \accepted{...}
  \journalname{...}
  \journalyear{...}
  \journalvolume{..}
  \journalissue{..}
  \startpage{1}
  \aop
  \DOI{...}

\maketitle

\section{Beispiele}

Die jüngere Forschung hat wiederholt die Rolle von Beispielen für die
Formierung von Wissen
unterstrichen \parencite{Ruchatz2007a,Schaub2010a,CL2013a,ZB}. Bislang
jedoch ist die Untersuchung von Beispielen stets selbst in einem
exemplarischen Modus geblieben: Einzelne Beispiele, von denen mehr
oder weniger plausibel ist, dass sie zentral für eine diskursive
Formation sind, sind detailliert und mit hermeneutischen Methoden oder
in dekonstruktionistischen Lektüren kommentiert worden. Für eine
Forschung, die auf einer größeren Menge von Beispielen basiert,
existiert schlicht keine strukturierte Datengrundlage.

Das DFG-Projekt \textit{Das Beispiel im Wissen der Ästhetik
  (1750--1850)} (FernUniversität in Hagen, Leitung Michael Niehaus)
hat sich einerseits das Ziel gesetzt, die Problemgeschichte der
Ästhetik von ihren Beispielen her anzugehen. Wie das funktionieren
kann, hat Derrida für Immanuel Kants \lit{Kritik der Urteilskraft}
vorgemacht, der im Zuge einer detaillierten Analyse von Kants
Begriffssystem konstatiert: »Eine Paradigmatik der Blume lenkt die
dritte \emph{Kritik}.« \Parencite[107]{Derrida1992} Neben ins Detail
von philosophischen Systemen und Argumentationen gehenden Analysen
will das Hagener Projekt jedoch auch die diskursive Praxis des
Beispielgebens archivieren -- ein Ziel ist die Gewinnung eines
Datensatzes aus einem Korpus von Schriften zur philosophischen
Ästhetik. Ein solcher hätte einen erheblichen Mehrwert für die
diskurstheoretische Erforschung des Beispiels im Sinne einer
Archäologie des Wissens nach \textcite{Fouc1997a}: Er würde die
Forschung in die Lage versetzen, i) ein Verzeichnis der Beispiele zu
präsentieren, ii) historische Längsschnitte zu tätigen, die Einblick
in die Häufigkeit einzelner Beispiele im Untersuchungszeitraum
gewähren -- ihre Emergenz, ihren Boom, ihr Verschwinden~-- und iii)
gegebenenfalls Trends im philosophischen Diskurs mit anderen Diskursen
zu korrelieren, z.B. mit der Reiseliteratur des 18., mit dem
Kolonialdiskurs des 19. Jahrhunderts oder mit der Botanik und
Biologie.

% \section{Kollektaneen, Annotationen und die Perspektive maschinellen Lernens}

Für das Erarbeiten eines Beispieldatensatzes gibt es verschiedene
Ansätze. Bereits vor einigen Jahren wurde begonnen, Beispiele durch
ein Webformular in einer Datenbank aufzunehmen.%
\footnote{\url{http://beispiel.germanistik.rub.de}} %
Neben der Textstelle, in der das Beispiel gegeben wird, und
Meta-Angaben über das Schriftstück ist dabei Folgendes erfasst worden:
das Beispiel selbst, also das eher Konkrete, was als Beispiel
angeführt wird; dasjenige, für das das Beispiel angeführt wird, also
das eher allgemeine Konzept, das mit dem Beispiel illustriert, belegt
oder verständlich gemacht wird; und ein optional vorhandener Marker
auf der Textoberfläche wie »z.\,B.«. Allerdings ist klar, dass die
Beispiele in solch einer Datenbank weitgehend ohne Kontext erfasst
werden: weitgehend ohne den begrifflich-argumentativen Kontext und
auch ohne den Kontext anderer Beispiele. Der Vorteil, dass man auf
diese Weise hinsichtlich der Textauswahl vom Urheberrecht weitgehend
uneingeschränkt bleibt, kann den Nachteil nicht aufwiegen, dass man am
Ende mit bloßen Kollektaneen dasteht. Die Exzerpte werden kaum
Datensatz dienen, auf dessen Grundlage durch maschinelles Lernen
weitere Beispiele in einem Korpus von Schriften gefunden werden
können.

Aus diesen Gründen setzt das DFG-Projekt \textit{Das Beispiel im
  Wissen der Ästhetik} auf die Annotation von Beispielen in
Volltexten. Allerdings gibt es sehr unterschiedliche Arten und Weisen,
Beispiele zu annotieren: Annotationen, die eher der
semantisch-propositionalen Struktur des Textes gerecht werden wollen,
und Annotionen, die eher im Zusammenhang mit linguistischen Kategorien
und mit in Algorithmen beschreibbaren Verfahren stehen.

\section{Beispiele in der propositionalen Struktur annotieren}

In einem literaturwissenschaftlichen Projekt mit einem philosophischen
Gegenstand wie der Ästhetik liegt es zunächst näher, die
semantische-propositionale Struktur von Beispielen in den Blick zu
nehmen und zu annotieren. Die Schwerkraft, welche die Idee der
Annotationen in diese Richtung zieht, hat ihren Grund in theoretischen
Annahmen über das Beispiel, die durch Definitionen im untersuchten
Korpus selbst bestätigt werden. So steht das Beispiel klassischerweise
im Zusammenhang mit der Beziehung zwischen dem Allgemeinen und dem
Besonderen; es kann einen allgemeinen Satz lediglich widerlegen, aber
nicht beweisen, hat aber einen epistemologischen Wert bei der
Induktion. %
(Aristoteles, \emph{Anal. pr.} II\,24; \cite[\see][]{Willer2007a}) %
Dieser epistemologischen Dimension des Beispiels muss man sicher noch
andere Dimensionen an die Seite stellen \parencite{CL2013b}: etwa eine
rhetorische Dimension, die auf den Beitrag zielt, den Beispiele im
Hinblick darauf leisten, dass ein Text zu seinem Ziel kommt und seine
Leser*innen überzeugt; oder eine konzeptuelle Dimension, nach der
Beispiele verwendete Begriffe klar machen (was weniger ist als ein
Widerlegen oder Belegen); oder eine normative Dimension, denn
Beispiele vermitteln -- gerade in der Ästhetik -- auch Konzepte, wie
etwas sein \emph{sollte} oder was man angesichts von einem Phänomen
der Natur oder Kunst empfinden \texttt{sollte}. -- Im Hinblick auf die
Annotationen bewirken solche theoretischen Überlegungen erst einmal,
dass die Idee, semantische Strukturen auszuzeichnen umso notwendiger
erscheint, sich aber gleichzeitig ein sehr komplexes
Annotationsunterfangen ankündigt. Die Annotationen sollen dann
Beispiele so erfassen, dass sie der theoretischen Idee vom Beispiel
möglichst gerecht werden und die \emph{formalisierte Beschreibung}
eines Phänomens, die Annotationen ihrer eigenen Idee nach sind, ein
Maximum an Expressivität im Hinblick auf die Beispiel-Theorie hat.

Eines der technischen Mittel mit der höchsten Experssivität für die
Formulierung von Vokabularen ist die \englisch{Web Ontology Language}
OWL. Das Vokabular zur Annotation von Beispielen ist in der OWL
realisiert \parencite{CL2018a}: Zur Auszeichnung von Textpassagen
dienen OWL-Klassen (owl:Class), von denen es im wesentlichen gibt:
Beispiel, Marker, Konzept und Kontext. Um Relationen zwischen
ausgezeichneten Textpassagen zu beschreiben, stehen
OWL-Objekteigenschaften (owl:ObjectProperty) zur Verfügung. So kann in
den Annotationen über einen Marker ausgesagt werden, welches Beispiel
er markiert, oder über ein Beispiel, für welches generellere Konzept
es als Beispiel angeführt wird, oder über ein Beispiel, in welchem
begrifflichen, argumentativen oder theoretischen Kontext es angeführt
wird. Solche der Prädikatenlogik ähnliche Aussagen werden immer als
Relation zwischen zwei ausgezeichneten Textpassagen annotiert, wobei
die Objekteingeschaft die Art der Relation beschreibt, die zwischen
den beiden Passagen besteht. Die OWL-Objekteigenschaften des
Vokabulars sind in einem Vererbungsbaum so organisiert, dass
z.\,B. alle Eigenschaften, mit denen eine Relation zwischen einem
Beispiel und einem Konzept beschrieben werden kann, von dem
Grund-Prädikat \vokabular{istBeispielFuer} abgeleitet sind. Dieses
Prädikat sagen per Vererbung (owl:subPropertyOf) insgesamt 24 weitere
Prädikate zur Beschreibung der Relation zwischen Beispiel und Konzept
aus, die in Teilbäumen organisiert sind. Mit diesem differenzierten
Vokabular an Prädikaten lassen sie die oben skizzierten Dimensionen
des Beispiels (epistemologisch, rhetorisch, konzeptuell, normativ)
einerseits auf formalisierte Art und Weise beschreiben und
andererseits bleibt dabei die elementare Relation zwischen einem
Beispiel und einem generellen Konzept, für das es angeführt wird,
aufgrund der Ableitung vom Grund-Prädikat \vokabular{istBeispielFuer}
stets mit ausgesagt. Das ist im Hinblick auf Abfragen auf dem
späteren Datensatz von besonderem Interesse. Darüber hinaus definiert
das Vokabular OWL-Dateneigenschaften (owl:DatatypeProperty), mit
welchen zu einer Textpassage freie Literale angegeben werden können.

Als Annotationswerkzeug kommt ein im Jahr 2015 selbst entwickeltes
Tool zum Einsatz, das mit dem in OWL definierten Vokabular umgehen
kann. Es basiert auf GNU Emacs, speichert die Annotationen als
Stand-Off-Markup und ermöglicht diskontinuierliches Markup.%
\footnote{\url{http://github.com/lueck/standoff-mode}. Zur Zeit der
  Entwicklung von \som\ standen noch keine Werkzeuge zur Verfügung,
  die diskontinuierliches Markup zusammen mit Relationen zwischen
  ausgezeichneten Textpassagen und eine Annotation von XML-
  bzw. TEI-Dokumenten ermöglicht haben. Das \englisch{BRAT Rapid
    Annotation Tool} kam den Anforderungen am nächsten, verarbeitet
  aber nur schlichte Text-Dateien. Das Datenmodell von CATMA hat
  Relationen noch nicht zugelassen und WebAnno war noch in der
  Entwicklungsphase, genau wie Funktionselemente von TextGrid.\par
  Zur Internalisierung des mit \som\ produzierten externen Markup in
  ein TEI-Dokument kommt ein in Haskell geschriebenes Programm zur
  Anwendung: \url{http://github.com/lueck/standoff-tools}.\par
  Das Vokabular zur Beschreibung von Beispielen ist online unter
  \url{http://github.com/lueck/standoff-mode/arb/arb.owl}.} %

Mit den der Prädikatenlogik ähnlichen Aussagen, die mit solch einem
Vokabular möglich sind, kann man die semantisch-propositionale
Struktur von Beispielen schon recht gut annotieren. Ein Beispiel aus
Kants dritter \lit{Kritik} \parencite[\pno\,77\psq (§\,17)]{KantKdU}:

\begin{quote}
  Schönheit ist die Form der Zweckmäßigkeit eines Gegenstandes, sofern
  sie ohne Vorstellung eines Zweckes an ihm wahrgenommen
  wird. [Fußnote:] Man könnte wider diese Erklärung als Instanz
  anführen, daß es Dinge gibt, an denen man eine zweckmäßige Form
  sieht, ohne an ihnen einen Zweck zu erkennen, z.\,B. die öfter aus
  alten Grabhügeln gezogenen, mit einem Loche als zu einem Hefte,
  versehenen steinernen Geräte; die, ob sie zwar in ihrer Gestalt
  deutlich eine Zweckmäßigkeit verraten, für die man den Zweck nicht
  kennt, darum gleichwohl nicht für schön erklärt werden. Allein, daß
  man sie für ein Kunstwerk ansieht, ist schon genug, um gestehen zu
  müssen, daß man ihre Figur auf irgend eine Absicht und einen
  bestimmten Zweck bezieht. Daher auch gar kein unmittelbares
  Wohlgefallen an ihrer Anschauung. Eine Blume hingegen, z.\,B. eine
  Tulpe, wird für schön gehalten, weil eine gewisse Zweckmäßigkeit,
  die so, wie wir sie beurteilen, auf gar keinen Zweck bezogen wird,
  in ihrer Wahrnehmung angetroffen wird.
\end{quote}

Man sieht sogleich, dass das Annotieren von Beispielen keine leichte
Aufgabe ist. Es gibt in der zitierten Passage zwei Beispiel-Marker
»z.\,B.« an der Text-Oberfläche, aber das ist auch schon alles, was
klar ist. Es ist ein erhebliches Maß an hermeneutischem Aufwand
erforderlich, um eine solche Passage zu annotieren; man muss also
schon ziemlich viel von Kants Argumentation und Begriffsystem
verstehen, um überhaupt sinnvoll etwas zu annotieren. Nur um eines
Einblicks willen: Es ist zwar klar, dass jeweils hinter den
Beispielmarkern »z.\,B.« das Beispiel folgt. Im zweiten Fall ist das
Beispiel »ein Blume«, im ersten Fall »die öfter aus alten
Grabhügeln gezogenen, mit einem Loche als zu einem Hefte, versehenen
steinernen Geräte; die, ob sie zwar in ihrer Gestalt deutlich eine
Zweckmäßigkeit verraten, für die man den Zweck nicht kennt, darum
gleichwohl nicht für schön erklärt werden«. Hier bekommt man gleich
einen Eindruck darüber, dass selbst die Bestimmung des Umfangs eines
Beispiels Schwierigkeiten machen kann: die lange Nominalphrase »öfter
die öfter aus alten Grabhügeln gezogenen, mit einem Loche als zu einem
Hefte, versehenen steinernen Geräte« gehört ganz sicher ganz zum
Beispiel, denn Teile dieser Phrase würden der intensionalen Bestimmung
des Beispiels nicht gerecht; es geht nicht um ›steinerne Geräte‹,
sondern um diejenigen ›steinerne Geräte‹, die man ›in alten
Grabhügeln‹ findet und die ›mit einem Loche als zu einem Hefte
versehen sind‹. Ohne diese Bestimmungen spricht man über eine viel
größere Klassen von Gegenständen. Aber man sieht auch gleich, dass man
die Nominalkonstruktion in Relativsätze umformen kann, und dann
entsteht die Frage, ob man den mit einem Semikolon abgetrennten
Relativsatz nicht auch zum Beispiel rechnen will. Andererseits wird in
ihm das Besondere des Beispiels mit dem Allgemeinen des Verhältnisses
zweier Begriffe, um die es geht, nämlich Zweckmäßigkeit und Schönheit,
verworben. Das wäre ein Argument, diesen Relativsatz, nicht mehr zum
Beispiel zu zählen. Im Gegensatz zu den Relativsätzen, die man durch
Auflösung der vorhergehenden Nominalkonstruktion erhält, handelt sich
um einen nicht-restriktiven Relativsatz, und man hätte gute Gründe für
die Regel, dass nicht-restriktive Relativsätze nicht mehr zum Beispiel
gehören sollen. Wenn man sie dennoch als Beispiel annotiert, dann
müsste man eigentlich auch noch den nächsten Satz zum Beispiel
hinzurechnen, da dort auch noch von den Grabbeigaben die Rede ist.

Im zweiten Fall von »ein Tulpe« ist die Lage nur auf den ersten Blick
klar. Auf den zweiten Blick bemerkt man, dass bereits »eine Blume« ein
Beispiel ist, das durch »z.\,B. eine Tulpe« noch einmal weiter
konkretisiert wird. Hier bilden also zwei Beispiele eine Art Kaskade
der Konkretisierung. Und man bemerkt weiter, dass es in der gesamten
Fußnote (die bis zum Ende des Zitats reicht) um Beispiele geht, denn
im ersten Satz der Fußnote heißt es, dass man gegen den allgemeinen
Obersatz »als Instanz« existierende Dinge mit bestimmten Eigenschaften
anführen könnte. Eine Instanz gegen etwas anzuführen, ist eine
Beispielpraxis, nämlich die des Gegenbeispiels, also des Widerlegens
einer allgemeinen Aussage mittels Beispielen. Ist dann aber »Dinge
[…], an denen man eine zweckmäßige Form sieht, ohne an ihnen einen
Zweck zu erkennen« bereits ein Gegenbeispiel in seiner allgemeinsten,
abstraktesten Form, die dann in den mit »z.\,B.« markierten Beispielen
konkretisiert wird, oder bloß die Form der dann folgenden konkreten
Beispiele?

Um die Relationen zwischen den Beispielen und dem allgemeinen Obersatz
annotieren zu können, muss man noch mehr von der Kantischen
Philosophie verstehen. Es geht hier um die Relation zwischen
Geschmacksurteil und der Wahrnehmung von Zwecken.%
\footnote{Zentral für das Begriffssystem und auch für die beiden hier
  besprochenen Beispiele ist die Unterscheidung zwischen freier und
  anhängender Schönheit. Vgl. dazu \textcite{Guesken2018a}.} %
Und in der Fußnote wird der Einwand erhoben (und nach Prüfung
verworfen), dass am Schönen Zwecke nicht
nicht % wichtig: doppeltes nicht
wahrgenommen, sondern nicht erkannt würden. Das erste Beispiel soll
als Beleg für diese Gegenthese herhalten und wird dann im Satz »Allein
…« zurückgewiesen. Das Beispiel der Blume Tulpe ist nicht ebenfalls
ein Gegenbeispiel, sondern ein Beispiel, das gegen die Gegenthese
gerichtet ist und somit den allgemeinen Obersatz unterstützt. Es soll
noch einmal klar machen, wie die Begriffe gemeint sind. Das Vokabular
zur Annotation nennt das die konzeptuelle Dimension eines
Beispiels. \Parencite[\see\ auch][]{CL2013b} Hier geht es darum, dass
die Blume Tulpe klar machen soll, wie es gemeint ist, dass sich das
Urteil, dass etwas schön sei, nicht auf den Zweck dieses Gegenstandes
bezieht. -- Derridas Verdikt, dass eine »Paradigmatik der Blume« Kants
Analytik des Schönen lenke, erweist sich schon als sehr instruktiv.

Solche Annotationen der propositionalen Struktur, in der Beispiele
gegeben werden, werden ziemlich komplex. Sie zu erstellen gleicht
einem \englisch{close reading} mit einem formalisierten
Beschreibungsvokabular. Mit der Komplexität steigt noch einmal der
zeitliche Aufwand, den manuelle Annotationen ohnehin schon
erfordern. Bei derartigen Investitionen stellt sich die Frage, was man
überhaupt mit solchen Annotationen hinterher anfangen will. Weil man
kaum ein ganzes Korpus ästhetischer Schriften wird annotieren können,
ist die Verwendung als Datensatz, an dem historische Längsschnitte
getätigt werden können, nicht oder nur sehr eingeschränkt gegeben. Die
Abfragemöglichkeiten, die aus einer Annotation entstehen, wären aber
sicher ein wichtiger Grund, den Aufwand zu betreiben. Wenn dies dann
jedoch nur in einem ganz eingeschränkten Umfang realisiert wird,
bleiben die Investitionen zweifelhaft.

Die zweite wichtige Verwendung wäre die als Datensatz für maschinelles
Lernen, aus dem mittels Regression die Parameter eines Algorithmus
gewonnen werden. Der Algorithmus wäre dann anschließend in der Lage
ist, selbstständig weitere Beispiele zu identifizieren. Das ist
natürlich immer eine Perspektive, die beim Annotieren eine Rolle
spielt und wegen der man sich um mehrere parallele Annotationen eines
Werks und ihre Deckungsgleichheit bemüht.%
\footnote{Vgl. den Beitrag von Evelin Gius und Nils Reiter im
  vorliegenden Band.} %
Allerdings zeigt die Projekterfahrung, dass bei solchen Annotationen,
die so komplex sind und bei denen so viel Verständnis des
Begriffssystems eingehen muss, dass Deckungsgleichheit kaum
herzustellen ist. Das betrifft nicht nur zwei unterschiedliche
Annotator*innen, sondern auch die Annotationen ein und derselben
Personen mit einer zeitlichen Differenz von einer Woche oder einem
Monat.%
\footnote{Über ähnliche Erfahrungen mit eigenen Annotationen berichtet
  auch McCarty in seinem Beitrag im vorliegenden Band.} %
Das ist aber nicht der einzige Punkt, der die Tauglichkeit der
Annotationen für \englisch{machine learning} infrage stellt. Es ist
auch kaum zu erwarten, dass in den überaus komplexen Strukturen, die
man auf diese Art und Weise annotiert, Muster stecken, die so an
anderen Stellen wieder identifiziert werden können und dann auch noch
tatsächlich Beispiele sind.

Dies und die Erfahrung, wie schwer übereinstimmende Annotationen zu
erreichen sind, gibt zu bedenken, ob Annotationen überhaupt Daten
sind. Reicht ihre formale Homogenität, die sie aufgrund der Verwendung
digitaler Tools haben, schon aus, um ihnen diesen Status zu
verleihen? %
Vielleicht sollte man Annotationen so handhaben, wie
\emph{Experimentalsysteme} in anderen Wissenschaften gehandhabt
werden, und die Frage ›Sind Annotationen Daten?‹ analog zur Frage, ob
ein experimenteller Aufbau, sobald er überhaupt irgendeinen Output
liefert, von Anfang an und jederzeit schon Daten produziert. Es ist
nämlich doch in anderen Wissenschaften nicht so: Hans-Jörg Reinberger
hat den Begriff des Experimentalsystems ja eingeführt, um zu
beschreiben, wie lange es dauert und welche in den Ergebnissen meist
ausgeblendeten Investitionen, länger verfolgten Abwege und welche kaum
jemals beschriebene Praxis in einen wissenschaftlichen Labor in den
Experimentalaufbau einfließen, bis ein Experiment endlich Daten
produziert, die etwas zu einer wissenschaftlich relevanten Frage
beitragen. Damit ist natürlich auch der Begriff der Daten als schlicht
Gegebenes infrage gestellt, denn an Stelle des Gegebenseins rückt mit
solch einer Beschreibung eine Labor-Praxis der Zurichtung in den
Blick. Deswegen ist es womöglich verfrüht, bereits bei der
übereinstimmenden Auszeichnung durch zwei oder mehrere Annotator*innen
von Daten zu sprechen. Ob der Experimentalaufbau funktioniert,
entscheidet sich ja erst dann, wenn die Annotationen mit einem
Algorithmus zusammentreffen. Das soll den Wert von Annotationen nicht
in Abrede stellen. Ohne Experimentalsysteme gäbe es ja schließlich gar
keine Daten. Allerdings scheint als Beschreibung des gegenwärtigen
Standes von Projekten in den auf Annotationen bauenden
literaturwissenschaftlichen DH der Begriff der Daten nicht passend: Es
handelt sich doch eher um Laborarbeit an Experimentalsystemen in einem
frühen Stadium.

\section{Re-Modellierung: Linguistik des Beispiels}

Der Mehrwert eines größeren Datensatzes an Beispielen wäre, wie
eingangs beschrieben, z.\,B. die Möglichkeit historischer
Längsschnitte. Für solche ist es gar nicht so interessant, in welcher
propositionalen Struktur ein Beispiel aufgerufen wird. Wichtiger ist
die Verwendung gleicher Beispiele, also gleicher Wörter. Ein
historischer Längsschnitt wird ja realisiert durch eine Abbildung der
Häufigkeit von Beispielen (Wörtern) auf einer Zeitleiste.

Das eröffnet die Perspektive für eine Re-Modellierung und drastische
Vereinfachung. Wenn einzelne Wörter oder Wortgruppen, die Beispiele
oder wenigstens ein zentraler Teil von Beispielen sind, in den Blick
genommen werden sollen, dann kann das Annotations-
bzw. Beschreibungsvokabular drastisch vereinfacht werden. Allerdings
muss auch ein neuer Term in das Vokabular eingeführt werden, nämlich
der \vokabular{Kopf} eines Beispiels. Während die Nominalphrase »ein
Tulpe« das \vokabular{Beispiel} ist, ist das Nomen »Tulpe« der
\vokabular{Kopf} dieses Beispiels. Im ersten Beispiel sieht man aber
gleich die Schwierigkeit, dass es oft nicht ganz leicht ist, denn Kopf
zu bestimmen: »Geräte«, »Hefte«, »Loche« oder »Grabhügeln«? Wenn der
Kopf eine ganz Nominalphrase sein darf, dann könnte man die ganze
Nominalkonstruktion »die öfter aus alten Grabhügeln gezogenen, mit
einem Loche als zu einem Hefte, versehenen steinernen Geräte« als Kopf
ansehen. Aber dies zeigt deutlich die sogleich eintretende
Komplexität, wenn man als Kopf mehr als ein Unigram (N-Gram mit N=1)
zulässt: Aufgrund der Produktionsregeln der Chomsky-Grammatik werden
die Köpfe dann potentiell unendlich lang bzw. komplex. Deswegen soll
zunächst versucht werden, bei der Re-Modellierung mit Unigram-Köpfen
auszukommen. Sollte sich herausstellen, dass dies nicht ausreicht,
dann könnte man ausgehend von einem Unigram die größte Nominalphrase,
in der es steht, zu bestimmen versuchen. Dies allerdings setzt gute
Resultate beim Parsen der Phrasenstruktur voraus, wovon bei
historischen Texten des 18. und 19. Jahrhunderts nicht immer
ausgegangen werden kann.

Also sei der \vokabular{Kopf} eines Beispiels definiert als dasjenige
einzelne Token (Unigram), das für das Beispiel signifikant ist. Es
sollte zu den Tokens gehören, die man mit dem oben beschriebenen
Vokabular (das auf die propositionelle Struktur, in der Beispiele
gegeben werden, zielt) als Beispiel annotiert hätte. Diese Definition
mag zu vage und deshalb unbefriedigend erscheinen. Sie ist aber nur so
unbefriedigend, wie es ebenfalls unbefriedigend ist, im ersten
zitierten Beispiel nur eines der Tokens »Geräte«, »Hefte«, »Loche« und
»Grabhügeln« als Kopf zu annotieren.


\section{Manuelle und maschinelle Annotationen}

Durch ein so reformuliertes und vereinfachtes Modell stellt sich auch
gleich die Frage nach Algorithmen, die die Annotation übernehmen
können. Verschiedenen Ansätze lassen sich denken. So bekommt man beim
Lesen von Schriften der philosophischen Ästhetik schnell den Eindruck,
dass eine ganzes Arsenal von Tieren und auch Pflanzen in ihnen als
Beispiele vorkommt: Pferde, Affen, Lerchen, Fledermäuse, Nashörner
usw. oder Rosen, Tulpen, Lilien usw. Man kann davon ausgehen, dass
Tiere fast immer als Beispiele angeführt werden. Die Schriften sind
schließlich keine botanischen Abhandlungen, sondern philosophische
Schriften zur einer Frage der sinnlichen Wahrnehmen, die sich aus der
Alltagswelt und den Schriften ihrer Zeit an Beispielen bedienen. Aber
man wäre ein Esel, wenn man sagen würde, das Tiere immer Beispiele
sind, denn manchmal kommen Tiere auch in Wendungen uneigentlichen
Sprechens vor. Man könnte also eine Tier- oder Pflanzen-Ontologie
verwenden, um Tier- und Pflanzennamen im Korpus zu suchen. Die
Vollständigkeit dieser Ontologien würde über die Genauigkeit
(\englisch{precision}), der Gebrauch metaphorischer Wendungen in den
Texten über die Trefferquote (\englisch{recall}) entscheiden. Bei
einem solchen Verfahren würde man ein äußeres Wissen, die Ontologie,
an den Text anlegen. 

Lassen sich auch Verfahren konstruieren, das Beispielwissen der Texte
selber zu erheben? Verfahren, die nicht mit einem vorgefertigten,
geschlossenen Wissen lediglich eine bestimmte semantische Teilmenge
(alle Tierbeispiele, alle Pflanzenbeispiele) identifizieren? Im
folgenden soll ein zweistufiges Verfahren vorgestellt werden. Es tritt
nicht an, um alle Beispiele in einem Korpus zu identifizieren. Aber es
soll möglichst viele mindestens einmal als Beispiel markierte
Beispiele identifizieren.

Im ersten Schritt macht sich das Verfahren zu nutze, dass das Beispiel
eine sprachliche Figur ist, die einen Marker an der Textoberfläche
haben kann. Es ist eine der wenigen Figuren mit einer
Standard-Abkürzungen als Oberflächenmarker. Das lateinische »e.\,g.«,
\latein{exempli gratia}, wörtlich \emph{um eines Beispiels willen}
oder \emph{aus Gunst des Beispiels}, ist in viele europäische Sprachen
übersetzt worden;%
\footnote{\Textcite[118]{Cappelli1990a} datiert die Entstehung der
  lateinische Abkürzung auf das 17. Jahrhundert und damit deutlich zu
  spät.} %
im Deutschen war im 18. Jahrhundert noch das »z.\,E.«, zum Exempel,
verbreitet, bevor es durch »z.\,B.« verdrängt worden ist.%
% \footnote{ Die Standard-Abkürzung weist nicht nur eine formale
%   Ähnlichkeit mit der Standard-Abkürzung »i.\,e.« auf, sondern auch
%   eine Ähnlichkeit in der Verwendung, denn beide werden dazu
%   verwendet, Begriff klar und deutlich zu
%   machen. \Parencite[\see][78--80]{CL2018a}} %
Die Standard-Abkürzung hat den Vorteil, dass man sich sicher sein,
kann, dass, wann immer sie auftaucht, ein Beispiel gegeben wird. --
Das ist zumindest in Schriften zur Ästhetik so, denn in ihnen werden
zwar Reflexionen über Beispiele und auch über das Geben und den
Gebrauch von Beispielen angestellt, aber keine metasprachlichen
Reflexionen über die sprachliche Form von Beispielen, geschweige denn
über die Verwendung dieses Markers. Die Auftauchen des Markers
»z.\,B.« kann also eindeutiger Indikator für das Vorhandensein eines
Beispiels angenommen werden. Auch andere Marker wie »bspw.« können als
eindeutig angesehen werden; andere hingegen nicht, so etwa »wie«, das
nur gelegentlich ein Beispiel markiert, meist aber als
Vergleichspartikel eingesetzt wird; Ähnliches gilt für »etwa«.

Die eindeutige Markierung ausnutzend soll in der ersten Phase des
Verfahrens der Kopf des Beispiels zu einem Marker identifiziert
werden. Es soll der Einfachheit halber davon ausgegangen werden, dass
der Kopf im selben Satz steht, wie der Marker. Das in dieser ersten
Phase zu lösende Problem ist ein Auswahl-Problem: Es stehen mehrere
Tokens als Kandidaten für einen Kopf zur Auswahl; die Auswahl muss
akzeptabel sein.

In der zweiten Phase des Verfahrens sollen anhand der in der ersten
Phase gefundenen Beispiel-Köpfe weitere, nicht markierte Beispiele
identifiziert werden. Für jedes weitere Vorkommen derselben Tokens im
Korpus ist also zu entscheiden, ob es sich um ein Beispiel handelt
oder nicht. Das in dieser zweiten Phase zu lösende Problem ist also
ein Entscheidungsproblem.

Mit diesem Verfahren wird man natürlich nicht alle Beispiele
erwischen, sondern höchstens diejenigen, die wenigstens einmal mit
einem eindeutigen Marker an der Textoberfläche markiert sind. Dieser
Abstrich ist zwar gravierend. Dafür verspricht aber das
Experimentalsystem mit diesem Verfahren viel eher Daten zu liefern als
bei der Annotation der propositionalen Struktur, in der Beispiele
gegeben werden. Denn nun können für jede Phase des Verfahrens zwei
sehr klare und einfache Annotationsaufgaben gestellt werden. Phase 1:
Annotiere in jedem Satz, in dem ein eindeutiger Beispiel-Marker
vorkommt, den Kopf des Beispiels. Phase 2: Annotiere zu jedem
Vorkommen der Tokens, die zur Menge der Beispiel-Köpfe gehören, ob es
sich um ein Beispiel handelt oder nicht. Die Chance ist jetzt viel
größer, dass die Annotationen der zwei Phasen zum Trainieren von
jeweils einem ML-Algorithmus geeignet sind. Für die zweite Phase kann
das z.\,B. das Entscheidungsbaum-Lernen
sein \parencite[105--120]{Beierle2014a}, für die erste Phase ein
Algorithmus wie der im Folgenden vorgestellte. In beiden Fällen ist es
dann noch von entscheidender Bedeutung, geeignete Merkmale zu
definieren und bereitzustellen, die für die Unterscheidung in Phase 1
der Kandidaten und in Phase 2 zwischen Ja und Nein relevant sind.

\subsection{Phase 1: Auswahl des Kopfes}

Wenn man Annotationen, Merkmale und Algorithmen gleich zusammen
konzipiert, lässt sich während des gesamten Prozesses der Modellierung
abschätzen, wie groß die Erfolgsaussichten sind, also die Aussichten
auf ein funktionierendes Experimentalsystem, in dem ein Algorithmus
brauchbare Daten produziert. Wenn man hingegen weder von einem
geeigneten Merkmalsraum noch von einem Algorithmus eine Vorstellung
hat, dann bleibt die Brauchbarkeit der Annotationen ein vages
Versprechen.

\subsubsection{Merkmalsraum}

In die Definition des Merkmalsraums werden \emph{Beobachtungen und
  Hypothesen} einfließen, die man beim Annotieren machen
bzw. aufstellen kann. Unserer Beobachtung zufolge sind Beispiel-Köpfe
meistens Nomen, seltener Vollverben, manchmal Adjektive, aber nie
Hilfverben, Artikel usw. Die Wortart wird also schon einmal zum
Merkmalsraum gehören.

Dann ist es auch von relevant, wie weit ein Token vom Marker entfernt
ist: Näher am Marker stehendes Token ist häufiger ein akzeptabler
Beispiel-Kopf als weiter weg stehende. Man kann die Distanz in Tokens
zählen oder auch in Kommata, die zwischen dem Marker und einem
Kandidaten stehen. Allerdings sieht man an Kants verschachtelten
Sätzen und Nominalkonstruktionen, dass diese einfachen Distanzmaße
auch trügerisch sein können und eine in Satzkonstituenten gemessene
Distanz noch besser wäre: In einer solchen wäre »Geräte« genauso weit
vom Marker entfernt wie »Grabhügeln«. Die Verwendung eines solchen
Maßes würde allerdings erneut gute Resultate beim Parsen der
Phrasenstruktur voraussetzen, wovon bei historischen Texten des
18. und 19. Jahrhunderts nicht immer ausgegangen werden kann. Des
Weiteren kann man beim Annotieren beobachten, dass der Marker dem
Beispiel meist, aber nicht immer vorangeht. Die Richtung zum Marker
gehört also auch zum Merkmalsraum.

Eine weitere Beobachtung ist, dass die Beispiel-Köpfe Wortformen
(Tokens) sind, die eher selten im Text vorkommen. Auch die zugehörigen
Zitierformen kommen eher selten vor. Diese Beobachtung kann man
machen, wenn man nach Häufigkeit geordnete Frequenztabellen der Tokens
eines Textes studiert. Die Beispielköpfe, die Nomen sind, kommen unter
den Nomen mit geringer bis mittlerer Häufigkeit vor, aber nicht unter
den häufigen Nomen. Die zehn häufigsten Nomen in Kants dritter Kritik
sind philosophische Begriffe: Natur (849 Mal), Begriff (746), Prinzip
(485), Zweck (438), Vernunft (404). Anhand dieser häufigen Wörter
werden Dokumente durch automatische Klassifikation vorgegebenen
Kategorien (Themenfeldern) zugeordnet \parencite{Sebastiani2002a} oder
durch Clustering gruppiert \parencite[195--209]{Heyer2006a}. Die Tier-
oder Pflanzen-Beispiele in Texten der philosophischen Ästhetik führen
nicht dazu, dass ein Text z.\,B. der Botanik zugeordnet wird oder mit
Linnés oder Okens Werken in einem Cluster auftaucht. Eine
linguistischen Grund dafür, dass Beispiele unter den Wörtern mit
geringer bis mittlerer Frequenz auftauchen, könnte in der
Thema-Rhema-Gliederung eines Textes gesucht
werden. \Parencite[784-786]{Bussm1990} An dieser Stelle interessiert
allerdings eher, dass die Frequenz ein relevantes Merkmal darstellt.

\subsubsection{Eine Funktion zur Bestimmung des Kopfes}

Formal kann die Aufgabe in Phase 1 folgendermaßen beschrieben
werden. Es ist eine Funktion $k$ zu bestimmen, die den Merkmalsvektor
$v_t\in V$ eines jeden Tokens eines Satzes mit einem eindeutigen
Beispielmarker auf das Interval der reellen Zahl zwischen 0 und 1
abbildet: $k:V \to [0,1]$, wobei $V$ der Merkmalsraum sei. Dasjenige
Token eines Satzes, für das $k$ maximal ist, soll der Kopf sein. Das
ist die Form, nach der das Auswahlproblem, das sich in Phase 1 stellt,
gelöst werden soll.

In der einfachsten Form könnte $k$ die normierte Summe der gewichteten
Merkmale sein bzw. die Summe von Funktionen, die den Merkmalsvektor
auswerten:
\begin{equation}
\label{eq:EinfacheGewichteteSumme}
k(v_t) = \sigma \left( \sum\limits_iw_if_i(v_t) \right)
\end{equation}
wobei $w_i$ die Gewichte und $f_i$ die Auswertfunktionen der Merkmale
seien, und $\sigma:\mathbb{R}\to [0,1]$ eine Normierungsfunktion ist
z.\,B. eine Schwanenhalsfunktion. Will man nicht nur die einzelnen
Merkmale auswerten, sondern Merkmalskombinationen, dass würde man $k$
als Summe von solcher Summen definieren:
\begin{equation}
  k(v_t) = \sigma\left[ \sum\limits_jw_j\sigma \left( \sum\limits_iw_{ji}f_i(v_t) +b_j\right)\right]
\end{equation}
Dann allerdings ist ein Vielfaches an Gewichten zu bestimmen und noch
zu jeder inneren Summe ein Schwellenwert $b_j$. Deshalb soll die
Definition nach Gleichung \ref{eq:EinfacheGewichteteSumme} ausreichen,
bei der man dann freilich die Normierungsfunktion zur Bestimmung des
Maximums weglassen kann.%
\footnote{Es gibt natürlich alternative Formen für $k$. Eine wäre ein
  Inferenznetzwerk mit
  Sicherheitsfaktoren \parencite[\see][90--96]{Beierle2014a}. Allerdings
  ist es dort schwieriger, Gewichte zu bestimmen.}

Die Gewichte können aufgrund der vorliegenden Annotationen durch
Regression gewonnen werden. Alternativ kann man versuchen, sie grob zu
schätzen, indem man überlegt, welches Merkmal wohl am wichtigsten ist,
welches am zweitwichtigsten usw. und dann noch versucht zu bestimmen,
wievielmal wichtiger das wichtigste Merkmal als die anderen Merkmale
ist. Das läuft dann auf ein hybrides Verfahren für die erste Phase
hinaus: Mit den geschätzten Gewichten generiert man eine Liste wie in
einem regelbasierten Verfahren. Diese unterzieht man einer Revision
und ersetzt diejenigen Köpfe, die nicht richtig annotiert worden
sind. Diese manuell korrigierte Liste verwendet man dann als Zielliste
anstelle der manuellen Annotationen im Volltext und versucht, bessere
Gewichte durch Regression zu bestimmen. Diese Liste besteht aus Tupeln
aus der ID des Satzes und der ID des Tokens, welches als Kopf bestimmt
worden ist. -- Auch dies würde ich eine Form von Annotationen nennen;
sie weist eine Ähnlichkeit mit Stand-Off-Markup%
\footnote{\Parencite[\see\ z.\,B.][575--579]{TEIP5} oder insbesondere
  das Text Corpus Format (TCF) von WebLicht:
  \url{https://weblicht.sfs.uni-tuebingen.de/weblichtwiki/index.php/The_TCF_Format}.} %
auf.

Das \englisch{preprocessing} der Texte aus dem Korpus wird durch
WebLicht erledigt. (Vgl. Abb.\,\ref{fig:Architektur}) Dieser
Webservice segmentiert einen Text nach Sätzen und Tokens, bestimmt zu
jedem Token eine Zitierform (Lemma) und die Wortart
(\englisch{Part-of-Speech-tag}, kurz PoS-tag). Die vorbereiteten Daten
werden in einer relationalen Datenbank abgelegt, deren Herzstück eine
Tabelle ist, in der jedes einzelne Token des Korpus in einer Zeile
repräsentiert wird, wobei die Spalten dieser Zeile die durch das
\englisch{preprocessing} gewonnenen Daten darstellen: die ID des
Tokens, die ID des Satzes, das Lemma, das PoS-tag und dann noch die ID
des Dokuments, mittels derer ein Token -- und damit auch die Beispiele
-- auf Metadaten wie Autor*in oder Jahr beziehbar wird. Durch das
\englisch{preprocessing} und durch elementare Abfragen dieser Tabelle,
die zu jedem Token die Frequenz ermitteln, werden also die
Merkmalsvektoren der Tokens generiert.


\subsubsection{Wortart}




\printbibliography

% Definition von Baumgarten zeigt die Komplexität

% mehrere Beispiele zu einem Marker, Beispielreihe.

\end{document}



%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% TeX-PDF-mode: t
%%% End:
